{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex1_cnn_mnist.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXfA6dWjgSxJ"
      },
      "source": [
        "#1. 패키지 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd_3fY8_gWA3"
      },
      "source": [
        "#2. GPU 사용 체크\n",
        "is_cuda=False\n",
        "if torch.cuda.is_available():\n",
        "    is_cuda = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2Al-EGIgZjZ"
      },
      "source": [
        "# 3. mnist 데이터 다운로드\n",
        "transformation = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_dataset = datasets.MNIST('data/',train=True,transform=transformation,download=True)\n",
        "test_dataset = datasets.MNIST('data/',train=False,transform=transformation,download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=32,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn5GKG59tqCP"
      },
      "source": [
        "#4. 네트워크 정의\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        #x = F.dropout(x,p=0.1, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x,dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uHtJstytrVl"
      },
      "source": [
        "#5. 모델 불러오기\n",
        "model = Net()\n",
        "if is_cuda:\n",
        "    model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toMnqcUPttOd"
      },
      "source": [
        "#6. 최적화 함수\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nme1Ei4Ktv_T"
      },
      "source": [
        "#7. 훈련 데이터 변수 준비\n",
        "data , target = next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zC5NWD_uI9j"
      },
      "source": [
        "#8. 훈련 및 검증 함수\n",
        "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
        "    if phase == 'training':\n",
        "        model.train()\n",
        "    if phase == 'validation':\n",
        "        model.eval()\n",
        "        volatile=True\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    for batch_idx , (data,target) in enumerate(data_loader):\n",
        "        if is_cuda:\n",
        "            data,target = data.cuda(),target.cuda()\n",
        "        data , target = Variable(data,volatile),Variable(target)\n",
        "        if phase == 'training':\n",
        "            optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output,target)\n",
        "        \n",
        "        #running_loss += F.nll_loss(output,target,size_average=False).data[0]\n",
        "        running_loss += F.nll_loss(output,target,reduction='sum').item()\n",
        "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
        "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "        if phase == 'training':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    \n",
        "    loss = running_loss/len(data_loader.dataset)\n",
        "    accuracy = 100. * running_correct/len(data_loader.dataset)\n",
        "    \n",
        "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
        "    return loss,accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWoj8C00uKlb"
      },
      "source": [
        "#9. 훈련\n",
        "train_losses , train_accuracy = [],[]\n",
        "val_losses , val_accuracy = [],[]\n",
        "for epoch in range(1,20):\n",
        "    epoch_loss, epoch_accuracy = fit(epoch,model,train_loader,phase='training')\n",
        "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,test_loader,phase='validation')\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracy.append(epoch_accuracy)\n",
        "    val_losses.append(val_epoch_loss)\n",
        "    val_accuracy.append(val_epoch_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nuig8SwyEbp"
      },
      "source": [
        "#10. 훈련 데이터와 검증 데이터의 손실 그래프\n",
        "plt.plot(range(1,len(train_losses)+1),train_losses,'bo',label = 'training loss')\n",
        "plt.plot(range(1,len(val_losses)+1),val_losses,'r',label = 'validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfjOdG1FyFAJ"
      },
      "source": [
        "#11. 훈련 데이터와 검증 데이터의 정확도 그래프\n",
        "plt.plot(range(1,len(train_accuracy)+1),train_accuracy,'bo',label = 'train accuracy')\n",
        "plt.plot(range(1,len(val_accuracy)+1),val_accuracy,'r',label = 'val accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}