{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyONB0zsd+Gkm+nNtXITbCa8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinFree/yolov5/blob/master/Train_YOLOv5_with_Pascal_VOC_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 노트북은 Colab에서 YOLOv5s 모델을 VOC dataset으로 훈련하는 예제입니다."
      ],
      "metadata": {
        "id": "PUWfSRIWqN9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "PASCAL VOC Dataset을 다운로드 받은 후 압축을 풀어줍니다."
      ],
      "metadata": {
        "id": "RDsWwsq6znDW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mI_yBQSxqFsb"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "!gdown 1w_WBizEt2e_u6T9iY-hkwA-fIVsJktbB\n",
        "!tar -xf VOCtrainval_11-May-2012.tar\n",
        "!rm VOCtrainval_11-May-2012.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실습하고 있는 데이터셋은 라벨링이 xml 파일 포맷으로 제공되며, 해당 포맷은 YOLOv5을 활용해 객체 인식 신경망을 훈련할 때 사용할 수 있는 파일 포맷이 아닙니다. \n",
        "\n",
        "convert2Yolo라고 하는 깃허브 저장소에서 Pascal VOC 데이터셋의 xml 파일 형태를 YOLOv5를 통한 훈련에 사용할 수 있도록 변환하는 기능을 제공합니다. 이를 활용해 xml 파일 포맷을 txt 파일 포맷으로 변환하겠습니다.\n",
        "\n",
        "이 과정에 앞서 다음과 같이 Pascal VOC 데이터셋의 클래스 리스트가 있는 파일을 생성합니다."
      ],
      "metadata": {
        "id": "BL9zIZyRqWL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"aeroplane\\n\", \"bicycle\\n\", \"bird\\n\", \"boat\\n\", \"bottle\\n\", \n",
        "           \"bus\\n\", \"car\\n\", \"cat\\n\", \"chair\\n\", \"cow\\n\", \"diningtable\\n\", \n",
        "           \"dog\\n\", \"horse\\n\", \"motorbike\\n\", \"person\\n\", \"pottedplant\\n\", \n",
        "           \"sheep\\n\", \"sofa\\n\", \"train\\n\", \"tvmonitor\"]\n",
        "with open(\"vocnames.txt\", 'w') as f:\n",
        "    f.writelines(classes)"
      ],
      "metadata": {
        "id": "ppAoE2IgqdQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vocnames.txt 파일이 생성된 것을 확인한 후 다음과 같이 VOCdevkit/VOC2012 폴더 아래에 labels 폴더를 생성한 후 convert2Yolo 저장소를 활용해 xml 파일을 txt 파일로 변환합니다"
      ],
      "metadata": {
        "id": "W7II6DerqmYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ssaru/convert2Yolo.git\n",
        "!cd convert2Yolo && python3 example.py --datasets VOC \\\n",
        "--img_path ../VOCdevkit/VOC2012/JPEGImages/ \\\n",
        "--label ../VOCdevkit/VOC2012/Annotations/ \\\n",
        "--convert_output_path ../VOCdevkit/VOC2012/JPEGImages/ \\\n",
        "--img_type \".jpg\" \\\n",
        "--manifest_path ../ \\\n",
        "--cls_list_file ../vocnames.txt"
      ],
      "metadata": {
        "id": "baDC2ukqqpU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다운로드 완료 후 훈련을 위한 이미지가 있는 폴더의 경로는 아래와 같습니다.\n",
        "\n",
        "/content/VOCdevkit/VOC2012/JPEGImages/ \n",
        "\n",
        "YOLOv5를 통한 객체 인식 신경망을 훈련하기 위해 각 이미지 내 객체의 위치가 라벨링되어 있는 텍스트 파일은 이미지와 같은 폴더에 있습니다.\n",
        "\n",
        "YOLOv5에서 훈련할 때 이미지와 같은 경로에 이미지와 동일한 이름의 라벨링 된 텍스트 파일이 있어야만 훈련을 수행할 수 있습니다. 구체적인 파일 구조는 아래와 같습니다.\n",
        "\n",
        "\n",
        "```\n",
        "$Object_Detection_Dataset/\n",
        "                         ┗ 1.png\n",
        "                         ┗ 1.txt\n",
        "                         ┗ 2.jpg\n",
        "                         ┗ 2.txt\n",
        "\n",
        "```\n",
        "\n",
        "이제 데이터를 훈련 데이터와 검증 데이터로 나누겠습니다."
      ],
      "metadata": {
        "id": "iAJ5FgXtqu48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "data_root = \"/content/VOCData\"\n",
        "val_root = os.path.join(data_root, \"val\")\n",
        "train_root = os.path.join(data_root, \"train\")\n",
        "os.makedirs(val_root, exist_ok=True)\n",
        "os.makedirs(train_root, exist_ok=True)\n",
        "\n",
        "with open(\"/content/manifest.txt\") as f:\n",
        "    files = f.readlines()\n",
        "\n",
        "for idx, img_path in tqdm(enumerate(files)):\n",
        "    img_src = img_path.split('\\n')[0]\n",
        "    txt_src = os.path.splitext(img_src)[0] + \".txt\"\n",
        "    img_name = os.path.split(img_src)[-1]\n",
        "    text_name = os.path.split(txt_src)[-1]\n",
        "    if idx % 10 < 3:\n",
        "        img_dst = os.path.join(val_root, img_name)\n",
        "        text_dst = os.path.join(val_root, text_name)\n",
        "    else:\n",
        "        img_dst = os.path.join(train_root, img_name)\n",
        "        text_dst = os.path.join(train_root, text_name)\n",
        "    shutil.copy2(img_src, img_dst)\n",
        "    shutil.copy2(txt_src, text_dst)"
      ],
      "metadata": {
        "id": "xraR6RcNt89z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 YOLOv5를 VOC dataset으로 훈련하도록 하겠습니다.\n",
        "\n",
        "학습을 위해 YOLOv5 환경을 구성하도록 하겠습니다."
      ],
      "metadata": {
        "id": "Bg6klYint-r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b v7.0 https://github.com/jetsonai/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install"
      ],
      "metadata": {
        "id": "5nzzGDf0tLpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련에 앞서 YOLOv5로 추론을 할 수 있는 환경인지 테스트해봅니다.\n",
        "\n",
        "검출은 아래와 같은 방식으로 할 수 있습니다.\n",
        "```\n",
        "python detect.py --source 0  # webcam\n",
        "                          img.jpg  # image \n",
        "                          vid.mp4  # video\n",
        "                          screen  # screenshot\n",
        "                          path/  # directory\n",
        "                         'path/*.jpg'  # glob\n",
        "                         'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
        "                         'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
        "```\n",
        "\n",
        "아래의 스크립트가 에러 없이 수행된다면 훈련할 준비가 되었습니다."
      ],
      "metadata": {
        "id": "Dio_bCsr2W_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(cv2.imread('runs/detect/exp/zidane.jpg'))"
      ],
      "metadata": {
        "id": "Lm4J-jdm2XOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 훈련을 위한 설정 파일을 준비합니다.\n",
        "\n",
        "YOLOv5에는 기본적으로 VOC 데이터셋을 훈련하기 위한 VOC.yaml파일이 있습니다만, 저희는 별도로 yaml파일을 제작합니다.\n",
        "\n",
        "내용은 아래와 같습니다.\n",
        "\n",
        "YOLOv5는 darknet을 사용하는 이전의 YOLOv4와는 다르게 데이터셋이 있는 폴더 경로를 입력하여서 훈련에 사용할 수 있습니다.\n",
        "\n",
        "```\n",
        "train: \n",
        "  - /content/VOCData/train\n",
        "val: \n",
        "  - /content/VOCData/val\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: aeroplane\n",
        "  1: bicycle\n",
        "  2: bird\n",
        "  3: boat\n",
        "  4: bottle\n",
        "  5: bus\n",
        "  6: car\n",
        "  7: cat\n",
        "  8: chair\n",
        "  9: cow\n",
        "  10: diningtable\n",
        "  11: dog\n",
        "  12: horse\n",
        "  13: motorbike\n",
        "  14: person\n",
        "  15: pottedplant\n",
        "  16: sheep\n",
        "  17: sofa\n",
        "  18: train\n",
        "  19: tvmonitor\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pf1DpMVVtors"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_lines = '''\n",
        "train:                          \n",
        "  - /content/VOCData/train      \n",
        "val:                            \n",
        "  - /content/VOCData/val        \n",
        "                                \n",
        "# Classes                       \n",
        "names:                          \n",
        "  0: aeroplane                  \n",
        "  1: bicycle                    \n",
        "  2: bird                       \n",
        "  3: boat                       \n",
        "  4: bottle                     \n",
        "  5: bus                        \n",
        "  6: car                        \n",
        "  7: cat                        \n",
        "  8: chair                      \n",
        "  9: cow                        \n",
        "  10: diningtable               \n",
        "  11: dog                       \n",
        "  12: horse                     \n",
        "  13: motorbike                 \n",
        "  14: person                    \n",
        "  15: pottedplant               \n",
        "  16: sheep                     \n",
        "  17: sofa                      \n",
        "  18: train                     \n",
        "  19: tvmonitor                 \n",
        "'''\n",
        "with open(\"/content/yolov5/vocdata.yaml\", 'w') as f:\n",
        "    f.write(text_lines)"
      ],
      "metadata": {
        "id": "izqGZ_BQtnPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 훈련을 수행하겠습니다."
      ],
      "metadata": {
        "id": "DpYp6zAOyAad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 480 --batch 16 --epochs 20 --data vocdata.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "id": "a3U9zCAFtVO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련이 완료되면 weight 파일을 다운로드합니다."
      ],
      "metadata": {
        "id": "3HrzXh810TRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/yolov5/runs/train/exp/weights/best.pt')"
      ],
      "metadata": {
        "id": "lDWOtKH-yvfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OMQot-ZBGc3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
