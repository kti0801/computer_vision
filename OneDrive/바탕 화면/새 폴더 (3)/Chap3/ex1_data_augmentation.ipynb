{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TorchVision을 이용한 데이터 증강"
      ],
      "metadata": {
        "id": "P59PQJNor7c_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtk-BdTu_T9T"
      },
      "outputs": [],
      "source": [
        "# 패키지 임포트\n",
        "from PIL import Image\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 데이터 다운로드"
      ],
      "metadata": {
        "id": "BcKjw8IeAyA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터 다운로드\n",
        "!wget https://raw.githubusercontent.com/jetsonai/DeepLearning4Projects/master/Chap3/data.zip"
      ],
      "metadata": {
        "id": "7GD3opQl8oMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#zip 파일 압축풀기\n",
        "!unzip data.zip -d data"
      ],
      "metadata": {
        "id": "G9tQs6mP_0RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 보기\n",
        "def cv_image_read(image_path):\n",
        "    print(image_path)\n",
        "    return cv2.imread(image_path)\n",
        "\n",
        "def show_image(cv_image):\n",
        "    rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure()\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "show_image(cv_image_read('./data/cat_2.jpg'))"
      ],
      "metadata": {
        "id": "7sHVq8dEmRf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Torchvision 데이터세트 클래스\n",
        "class TorchvisionDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        file_path = self.file_paths[idx]\n",
        "        # 이미지 읽기\n",
        "        image = Image.open(file_path)\n",
        "        # 이미지 변경 수행\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "ntIfOPzuNvUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Torchvision 이미지 변형 (사이즈 변경, 자르기, 수평 뒤집기)\n",
        "torchvision_transform = transforms.Compose([\n",
        "    transforms.Resize((220, 220)),\n",
        "    transforms.RandomCrop(120),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "# TorchvisionDataset 클래스 객체 생성\n",
        "torchvision_dataset = TorchvisionDataset(\n",
        "    file_paths=['./data/cat_2.jpg'],\n",
        "    labels=[1],\n",
        "    transform=torchvision_transform,\n",
        ")"
      ],
      "metadata": {
        "id": "N8sGXme_I4Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤으로 2번 변형 수행\n",
        "for i in range(2):\n",
        "  sample, _= torchvision_dataset[0]\n",
        "  plt.figure()\n",
        "  plt.imshow(transforms.ToPILImage()(sample))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "U8egvZniOBnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Albumentations 패키지를 이용한 데이터 증강"
      ],
      "metadata": {
        "id": "5tRslX_atWbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations\n",
        "import albumentations.pytorch"
      ],
      "metadata": {
        "id": "fto9P1wcAtZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Albumentations 데이터세트 클래스\n",
        "class AlbumentationsDataset(Dataset):\n",
        "    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        file_path = self.file_paths[idx]\n",
        "        # 이미지 읽기\n",
        "        image = cv2.imread(file_path)\n",
        "        # BGR opencv 이미지를 RGB 이미지로 변경\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        # 이미지 변경 수행\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "194IYOMJpSh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# albumentations 이미지 변형 (사이즈 변경, 자르기, 90도 회전, 수평 뒤집기, 가우시안 노이즈)\n",
        "albumentations_transform = albumentations.Compose([\n",
        "    albumentations.Resize(220, 220),\n",
        "    albumentations.RandomCrop(120, 120),\n",
        "    albumentations.RandomRotate90(p=1),\n",
        "    albumentations.HorizontalFlip(),\n",
        "    albumentations.GaussNoise(p=1),\n",
        "    albumentations.pytorch.transforms.ToTensorV2()\n",
        "])\n",
        "#AlbumentationsDataset 클래스 객체 생성\n",
        "albumentations_dataset = AlbumentationsDataset(\n",
        "    file_paths=['./data/cat_2.jpg'],\n",
        "    labels=[1],\n",
        "    transform=albumentations_transform,\n",
        ")"
      ],
      "metadata": {
        "id": "AmuqGFDnpUzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤으로 2번 변형 수행\n",
        "for i in range(2):\n",
        "  sample, _ = albumentations_dataset[0]\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(transforms.ToPILImage()(sample))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "BuplaIiNpYJP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}